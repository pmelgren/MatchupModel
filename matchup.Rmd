---
title: "XGBoost Matchup Model"
author: "Pete Melgren"
date: "August 21, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(baseballr) # installed from github.com/BillPetti/baseballr
library(data.table) # use data.table package to optimize speed
library(ggplot2)
library(Matrix)
library(xgboost)
```

## Data Preparation

Begin by bringing in the event data from the publicly available retrosheet database. Instructions on bringing retrosheet into an SQL table can be found [here](github.com/pmelgren/baseballdatabase) or [here](https://tht.fangraphs.com/databases-for-sabermetricians-part-one/).

Next import the statcast data and aggregate relevant variables by player and pitch type.
```{r scrape data, cache = TRUE}
#import statcast data in multiple chunks to prevent timeout. This will take a few minutes.
if(!exists("sc")){ # use this if statement to prevent unnecessarily scraping the same data multiple times so as to not abuse the site.
  sc = data.frame()
  start = as.Date("2018-03-29")
  end = start+6
  while(start < as.Date("2018-10-01")){
    sc = rbind(sc,scrape_statcast_savant(start,end))
    start = start + 7
    end = end + 7
  }
}

# set sc to a data.table to optimize for speed
sc = data.table(sc)

# filter out only regular season
sc = sc[game_type == "R"]

# add binary indicators for if the pitch was in-zone and if the batter swung
sc[,inzone := ifelse(abs(plate_x)<.75 & plate_z<sz_top & plate_z>sz_bot, 1, 0)]
sc[grep("hit_in?|swing?|foul|foul?|?bunt",description),swing := 1]
sc[is.na(swing), swing := 0]
sc[grep("?ball|hit_by_pitch|pitchout",description),strike := 0]
sc[is.na(strike), strike := 1]
```

```{r aggregate pitchers}
# aggregate pitcher data into a few key metrics
p_agg = sc[,list(P.pit = length(batter)
                 ,wOBA.pit = sum(woba_value,na.rm = TRUE) /
                   sum(woba_denom,na.rm = TRUE)
                 ,FF_pct = mean(pitch_type == "FF",na.rm = TRUE)
                 ,SI_pct = mean(pitch_type == "SI",na.rm = TRUE)
                 ,SL_pct = mean(pitch_type == "SL",na.rm = TRUE)
                 ,CH_pct = mean(pitch_type %in% c("CH","FS"),na.rm = TRUE)
                 ,CB_pct = mean(pitch_type %in% c("CU","KC"),na.rm = TRUE)
                 ,FB_Velo = mean(ifelse(pitch_type %in% c("FF","SI")
                                        ,release_speed,NA),na.rm = TRUE)
                 ,SL_Velo = mean(ifelse(pitch_type == "SL"
                                        ,release_speed,NA),na.rm = TRUE)
                 ,SL_Spin = mean(ifelse(pitch_type == "SL"
                                        ,release_spin_rate,NA),na.rm = TRUE)
                 ,CB_Spin = mean(ifelse(pitch_type %in% c("CU","KC")
                                        ,release_spin_rate,NA),na.rm = TRUE)
                 ,Extension = mean(release_extension,na.rm =TRUE)
                 ,LA.pit = mean(launch_angle,na.rm = TRUE)
                 ,Strike_pct = mean(strike,na.rm = TRUE)
                 ,Zone_pct = mean(zone,na.rm = TRUE))
           ,by = pitcher]
str(p_agg)
summary(p_agg)
```

```{r aggregate batters}
# aggregate batter data
b_agg = sc[,list(P.bat = length(pitcher)
                 ,wOBA.bat = sum(woba_value,na.rm = TRUE) / 
                   sum(woba_denom,na.rm = TRUE)
                 ,Exit_velo = mean(launch_speed,na.rm = TRUE)
                 ,LA.bat = mean(launch_angle,na.rm = TRUE)
                 ,Swing_pct = sum(swing)/length(pitcher)
                 ,Whiff = sum(description == "swinging_strike")/sum(swing)
                 ,Chase = sum(swing*(1-inzone),na.rm = TRUE)/length(pitcher)
                 ,Zcontact = (sum(inzone*swing*(description != "swinging_strike")
                                  ,na.rm = TRUE)/sum(inzone*swing,na.rm = TRUE)))
           ,by = batter]
str(b_agg)
summary(b_agg)
```

```{r event data}
events = sc[woba_denom == 1
            ,list(pitcher,batter,inning
                  ,outs = outs_when_up
                  ,b_side = stand
                  ,p_throws
                  ,score_diff = home_score-away_score
                  ,base_state = as.factor(paste0(ifelse(is.na(on_1b),"1","_")
                                                 ,ifelse(is.na(on_2b),"2","_")
                                                 ,ifelse(is.na(on_3b),"3","_")))
                  ,woba_value
                  
                  )
            ]
str(events)
summary(events)
```

With our 3 tables in place, we can now combine them into one table that we'll use to train the model.
```{r join datasets}
model_dat = merge(events,p_agg,by = c("pitcher"))
model_dat = merge(model_dat,b_agg,by = c("batter"))

str(model_dat)
summary(model_dat)
```

Right away we notice that the pitcher and batter id's are treated as numeric data when they should be categorical. But before we do that conversion, we also need to account for the pitchers and batters that have a really small sample size. So what we'll do is mask the ID of any pitcher or batter that doesn't meet a certain pitch threshold. So let's explore what that threshold should be.

We'll begin by plotting density of pitchers and batters by pitch_count to try to get a good idea of what a reasonable masking threshold might be.
```{r masking eploration plot}
plot_dat = data.table(P = p_agg$P.pit, Position = "Pitcher")
plot_dat = rbind(plot_dat,data.table(P= b_agg$P.bat, Position = "Batter"))
ggplot(plot_dat,aes(x = P, color = Position)) + 
  stat_ecdf(size = 1) + 
  labs(y = "Cumulative Percentage"
       ,title = "Cumulative Percentage of Players by Pitch Threshold")
rm(plot_dat)
```

Based on this, it looks like 200 pitches is a reasonable cutoff to mask the ID's of both pitchers and batters. Although it will mask more batters, there are more total batters in the sample. Just to verify this Let's look at how many players will remain unmasked for each catergory.
```{r unmasked numbers}
print(paste("Pitchers:",nrow(p_agg)-nrow(p_agg[P.pit < 200])," of ",nrow(p_agg)))
print(paste("Batters:",nrow(b_agg)-nrow(b_agg[P.bat < 200])," of ",nrow(b_agg)))
```

We lose a high percentage of batters, but still have a large number of players in each category, so we'll stick with 200. Then once we've masked these players we can go ahead and convert the variables to categrical.
```{r masking}
# mask pitcher and batter ID's with fewer than 200 pitches
model_dat[P.pit < 200, pitcher := 0]
model_dat[P.bat < 200, batter := 0]

# convert to factors to indicate they're categorical variables
model_dat[,pitcher := as.factor(as.character(pitcher))]
model_dat[,batter := as.factor(as.character(batter))]

str(model_dat)
```

Now that our data is ready, we can prepare it for our model by converting to a matrix. We're going to use a sparse matrix given the high number of categorical columns in our data.

```{r convert to matrix}
options(na.action='na.pass')
train_dat = sparse.model.matrix(woba_value~.,data = model_dat)
dim(train_dat)
```

Now we'll set up an initial grid search. R doesn't have good support of grid search functionality for sparse model matrixes so we'll do it manually using a for loop.

The first thing we want to determine is the optimum tree depth (interactions). So we'll begin by searching over tree depths of various lengths with a high learning rate.

```{r first grid search, cache=TRUE}
#create a data frame to store the output of the tuning exercies
tune_results = data.frame()
tunecv = list()
rnum = 1

# Set the preliminary tuning parameters
d = seq(1,7,2)
lr = c(.1)

# begin by identifying the best tree depth
for(i in 1:length(d)){
  for(j in 1:length(lr)){
    
    print(paste("Depth of",d[i],"and learning rate of",lr[j]))
    
    # calculate cross-validated tuning metrics
    tunecv[[rnum]] = xgb.cv(data = train_dat
                            ,label = model_dat$woba_value
                            ,max.depth = d[i]
                            ,eta = lr[j]
                            ,nround = 5000
                            ,objective = "reg:squarederror"
                            ,nfold = 5
                            ,early_stopping_rounds = 100
                            ,verbose = TRUE
                            ,print_every_n = 100
                            )
    
    #add data to the output variable
    tune_results = rbind(tune_results
      ,data.frame(depth = d[i]
                  ,lr = lr[j]
                  ,min_err = min(tunecv[[rnum]]$evaluation_log$test_rmse_mean)
                  ,best_iter = tunecv[[rnum]]$best_iter))
    rnum = rnum+1
  }
}
```
```{r plot first grid search}
plotdat = data.table()
for(i in 1:length(tunecv)){
  plotdat = rbind(plotdat
                  ,data.table(test_rmse = tunecv[[i]]$evaluation_log$test_rmse_mean
                              ,params = paste0("d:",tunecv[[i]]$params$max_depth
                                               ,"_lr:",tunecv[[i]]$params$eta)
                              ,iter = tunecv[[i]]$evaluation_log$iter))
}
ggplot(plotdat,aes(iter,test_rmse,color = params))+ geom_line() + 
  coord_cartesian(ylim = c(.511,.52))

plotdat[test_rmse == min(test_rmse)]
```

We'll refine the grid search now by eliminating the larger tree depths that didn't perform well and trying lower learning rates.

```{r second grid search, cache = TRUE}
# Set the preliminary tuning parameters
d = 1:3
lr = c(.05,.025,.01)

# begin by identifying the best tree depth
for(i in 1:length(d)){
  for(j in 1:length(lr)){
    
    print(paste("Depth of",d[i],"and learning rate of",lr[j]))
    
    # calculate cross-validated tuning metrics
    tunecv[[rnum]] = xgb.cv(data = train_dat
                            ,label = model_dat$woba_value
                            ,max.depth = d[i]
                            ,eta = lr[j]
                            ,nround = 5000
                            ,objective = "reg:squarederror"
                            ,nfold = 5
                            ,early_stopping_rounds = 100
                            ,verbose = TRUE
                            ,print_every_n = 100
                            )
    
    #add data to the output variable
    tune_results = rbind(tune_results
      ,data.frame(depth = d[i]
                  ,lr = lr[j]
                  ,min_err = min(tunecv[[rnum]]$evaluation_log$test_rmse_mean)
                  ,best_iter = tunecv[[rnum]]$best_iter))
    rnum = rnum+1
  }
}
```
```{r plot second grid search}
plotdat = data.table()
for(i in 1:length(tunecv)){
  if(tunecv[[i]]$params$max_depth <= 3){
      plotdat = rbind(plotdat
                  ,data.table(test_rmse = tunecv[[i]]$evaluation_log$test_rmse_mean
                              ,params = paste0("d:",tunecv[[i]]$params$max_depth
                                               ,"_lr:",tunecv[[i]]$params$eta)
                              ,iter = tunecv[[i]]$evaluation_log$iter))
  }
}
ggplot(plotdat,aes(iter,test_rmse,color = params))+geom_line() + 
  coord_cartesian(ylim = c(.511,.512))

best = which(tune_results$min_err == min(tune_results$min_err))
tune_results[best,]
```

```{r train model}
model.xgb = xgboost(data = train_dat
                    ,label = model_dat$woba_value
                    ,max.depth = tune_results$depth[best]
                    ,eta = tune_results$lr[best]
                    ,nround = tune_results$best_iter[best]
                    ,objective = "reg:squarederror"
                    ,metric = "rmse"
                    ,verbose = TRUE
                    ,print_every_n = 50)
```

```{r feature importance}
imp = xgb.importance(train_dat@Dimnames[[2]], model = model.xgb)
imp
```

A few things stand out. First of all, 97% of the model gain is explained by pitcher and batter average wOBA. It makes sense that wOBA at a aggregate level would explain wOBA at a plate-appearance level. It also helps to explain why the model gains are so small after the initial iteration. 
Secondly, we see that only 55 of the 1180 features are used at all. My suspicion is that the unused features are almost entirely pitcher and batter id's, but let's verify this. 

```{r explore unused features}
unused = train_dat@Dimnames[[2]][!train_dat@Dimnames[[2]] %in% imp$Feature]
unused[-grep("pitcher?|batter?",unused)]
```

So a fair number of non-ID features are ignored as well, mostly related to pitch usage rate and base states.

Because so many pitcher/batter features are unused, next we want to see if we can adjust our masking threshold to something more useful for the model. So let's compare the total pitches of used and unused pitchers and batters.
```{r set higher pitch thresholds}
used_pitchers = substr(imp$Feature[grep("pitcher?",imp$Feature)],8,13)
used_batters = substr(imp$Feature[grep("batter?",imp$Feature)],7,12)

print("Used Features")
summary(p_agg[pitcher %in% used_pitchers,"P.pit"])
summary(b_agg[batter %in% used_batters,"P.bat"])

print("Unused Features")
summary(p_agg[!pitcher %in% used_pitchers,"P.pit"])
summary(b_agg[!batter %in% used_batters,"P.bat"])
```

The mean pitch count for both pitchers and batters that are used in the model is significantly higher than those without. So we'll try raising the threshhold and respecifying the model to see if we can lower our CV error.

```{r train data for higher thresholds}
i = 2
train_dat_list = list(train_dat)
for(n in c(1000,2000)){
  # convert pitcher and batter back to characters
  model_dat[,pitcher := as.character(pitcher)]
  model_dat[,batter := as.character(batter)]
  
  
  # mask pitcher and batter ID's with fewer than 200 pitches
  model_dat[P.pit < n, pitcher := "0"]
  model_dat[P.bat < n, batter := "0"]
  
  # convert to factors to indicate they're categorical variables
  model_dat[,pitcher := as.factor(pitcher)]
  model_dat[,batter := as.factor(batter)]
  
  # convert to a sparse model matrix using the higher threshold
  train_dat_list[[i]]= sparse.model.matrix(woba_value~.,data = model_dat)
  print(dim(train_dat_list[[i]]))
  
  i = i+1
}
```

With training data for the higher thresholds in place, we'll now re-tune the model with the 2 new training data matricies to find the optimum number of iterations. Given how close our results were last time, it's probably wise to grid search this over a depth of both 1 and 2.
```{r grid search with different thresholds, cache = TRUE}
threshold_tune = list()
rnum = length(tunecv)+1

depth = c(1,2)
tune_results$masking_threshold = 200
for(d in depth){
  for(td in 2:3){
    tunecv[[rnum]] = xgb.cv(data = train_dat_list[[td]]
                            ,label = model_dat$woba_value
                            ,max.depth = d
                            ,eta = .025
                            ,nround = 5000
                            ,objective = "reg:squarederror"
                            ,nfold = 5
                            ,early_stopping_rounds = 100
                            ,verbose = TRUE
                            ,print_every_n = 100
                            )
    tune_results = rbind(tune_results
      ,data.frame(depth = d
                  ,lr = .025
                  ,min_err = min(tunecv[[rnum]]$evaluation_log$test_rmse_mean)
                  ,best_iter = tunecv[[rnum]]$best_iter
                  ,masking_threshold = ifelse(td == 2,1000,2000)
                  )
      )
    rnum = rnum+1  }
}
```
```{r plot third grid search}
plotdat2 = data.table()
for(i in 1:length(tunecv)){
  if(tune_results$masking_threshold[i] != 200){
      plotdat2 = rbind(plotdat2
        ,data.table(test_rmse = tunecv[[i]]$evaluation_log$test_rmse_mean
                    ,params = paste0("d:",tunecv[[i]]$params$max_depth
                                               ,"_lr:",tunecv[[i]]$params$eta)
                    ,masking_threshold = as.character(tune_results$masking_threshold[i])
                    ,iter = tunecv[[i]]$evaluation_log$iter))
  }
}
ggplot(plotdat2,aes(iter,test_rmse, color = params
                    ,linetype = masking_threshold)) +
  geom_line() + coord_cartesian(ylim = c(.51,.52))

print("Best iteration from new thresholds:")
print.data.frame(plotdat2[test_rmse == min(test_rmse)])
print("Best iteration from original threshold:")
print.data.frame(plotdat[test_rmse == min(test_rmse)])
```

